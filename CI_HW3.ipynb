{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (1.2.2)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Collecting matplotlib!=3.6.1,>=3.1 (from seaborn)\n",
      "  Using cached matplotlib-3.7.1-cp310-cp310-win_amd64.whl (7.6 MB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.1->seaborn)\n",
      "  Using cached contourpy-1.0.7-cp310-cp310-win_amd64.whl (162 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.1->seaborn)\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.1->seaborn)\n",
      "  Using cached fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib!=3.6.1,>=3.1->seaborn)\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Collecting pillow>=6.2.0 (from matplotlib!=3.6.1,>=3.1->seaborn)\n",
      "  Using cached Pillow-9.5.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.1->seaborn)\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\tbook\\s8\\ci\\projects\\3\\fuzzy_logic_sms_spam_filtering\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.4 kiwisolver-1.4.4 matplotlib-3.7.1 pillow-9.5.0 pyparsing-3.0.9 seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "## install the libraries needed\n",
    "!pip install -U numpy pandas scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(sms_data_str):\n",
    "    \"\"\"\n",
    "    convert `sms_data_str` into a pandas dataframe\n",
    "    \"\"\"\n",
    "    data_arr = []\n",
    "\n",
    "    data_records = sms_data_str.split('\\n')[:-1]\n",
    "    for data in data_records:\n",
    "        label = None\n",
    "        sample = None\n",
    "        match data[:3]:\n",
    "            case 'ham':\n",
    "                label = 'legitimate'\n",
    "                sample = data[4:] \n",
    "            case 'spa':\n",
    "                label = 'spam'\n",
    "                sample = data[5:] \n",
    "            case _:\n",
    "                label = 'N/A'\n",
    "            \n",
    "        data_arr.append([label, sample])\n",
    "        \n",
    "    data_arr = np.array(data_arr)\n",
    "    data_label = data_arr[:, 0]\n",
    "    data_records = data_arr[:, 1]\n",
    "    \n",
    "    return data_records, data_label\n",
    "\n",
    "def tfidf_vectorizer(records):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        token_pattern=r'\\b[A-Za-z]+\\b', \n",
    "        norm=None\n",
    "    )\n",
    "    \n",
    "    records_transformed = vectorizer.fit_transform(records)\n",
    "\n",
    "    return records_transformed.toarray(), vectorizer.get_feature_names_out()\n",
    "\n",
    "def feature_extraction(X, n_components=5):\n",
    "    reduction_pca = PCA(\n",
    "        n_components=n_components,\n",
    "        whiten=False\n",
    "    )\n",
    "    data_reduced = reduction_pca.fit_transform(X)\n",
    "    return data_reduced\n",
    "\n",
    "def feature_selection(df_records, labels, n_components=5):\n",
    "    feature_selection_model = SelectKBest(mutual_info_classif, k=n_components) \n",
    "    ## make a selection over the best features\n",
    "    selected_record_features = feature_selection_model.fit_transform(df_records, labels)\n",
    "    \n",
    "    return selected_record_features, feature_selection_model.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data_str = None\n",
    "with open('SMSSpamCollection') as file:\n",
    "    sms_data_str = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, labels = process_data(sms_data_str)\n",
    "records_vectorized, feature_names = tfidf_vectorizer(records)\n",
    "\n",
    "## one hot encoding labels\n",
    "labels = np.array([0 if y == 'legitimate' else 1 for y in labels] )\n",
    "\n",
    "## reducing dimension\n",
    "records_dim_reduced = feature_extraction(records_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.85636295,  0.28498098, -1.18436733,  0.8202903 ,  0.7139498 ],\n",
       "       [-2.78398936,  0.52112531, -1.74208375,  0.50130123, -0.73125667],\n",
       "       [ 0.48304914, -0.03714641,  2.01782298, -6.52899362,  1.04211524],\n",
       "       [-1.83557415,  1.13896758, -3.93125052, -0.18463624, -1.97520023],\n",
       "       [ 0.27696323, -0.77676797,  0.11525717,  1.31799112, -0.7573179 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_dim_reduced[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_vectorized = pd.DataFrame(records_vectorized, columns=feature_names)\n",
    "\n",
    "records_selection, feature_name_selection = feature_selection(records_vectorized,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "      <th>free</th>\n",
       "      <th>i</th>\n",
       "      <th>to</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.352406</td>\n",
       "      <td>0.213381</td>\n",
       "      <td>1.072582</td>\n",
       "      <td>0.887113</td>\n",
       "      <td>0.143342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.102998</td>\n",
       "      <td>1.126930</td>\n",
       "      <td>1.797171</td>\n",
       "      <td>1.586578</td>\n",
       "      <td>0.849520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.992194</td>\n",
       "      <td>2.194748</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.937499</td>\n",
       "      <td>12.563905</td>\n",
       "      <td>23.906328</td>\n",
       "      <td>17.557983</td>\n",
       "      <td>13.542179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              call         free            i           to          txt\n",
       "count  5574.000000  5574.000000  5574.000000  5574.000000  5574.000000\n",
       "mean      0.352406     0.213381     1.072582     0.887113     0.143342\n",
       "std       1.102998     1.126930     1.797171     1.586578     0.849520\n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000\n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000\n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000\n",
       "75%       0.000000     0.000000     1.992194     2.194748     0.000000\n",
       "max       9.937499    12.563905    23.906328    17.557983    13.542179"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for better visualization\n",
    "pd.DataFrame(records_selection, columns=feature_name_selection).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  1\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(labels).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    records_selection, labels, test_size=0.2, random_state=42, shuffle=True, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.99219404, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 2.19474792, 4.51405981],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: build a fuzzy rule-based model for (records, label)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3734,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_true = []\n",
    "y_train_true = []\n",
    "X_test_true = []\n",
    "y_test_true = []\n",
    "mask = [0 for i in range(5574)]\n",
    "cnt = 0\n",
    "for i in range(5574):\n",
    "\n",
    "    if labels[i] == 0:\n",
    "        X_train_true.append(records_selection[i])\n",
    "        y_train_true.append(labels[i])\n",
    "        mask[i] = 1\n",
    "        cnt +=1\n",
    "    if cnt >= 500:\n",
    "        break\n",
    "\n",
    "cnt = 0\n",
    "for i in range(5574):\n",
    "    if labels[i] == 1:\n",
    "        X_train_true.append(records_selection[i])\n",
    "        y_train_true.append(labels[i])\n",
    "        mask[i] = 1\n",
    "        cnt +=1\n",
    "    if cnt >= 500:\n",
    "        break\n",
    "cnt = 0\n",
    "for i in range(5574):\n",
    "    if labels[i] == 0 and mask[i] == 0:\n",
    "        print(\"ok\")\n",
    "        X_test_true.append(records_selection[i])\n",
    "        y_test_true.append(labels[i])\n",
    "        cnt +=1\n",
    "    if cnt >= 200:\n",
    "        break\n",
    "cnt = 0\n",
    "for i in range(5574):\n",
    "    if labels[i] == 1 and mask[i] == 0:\n",
    "        print(\"ok\")\n",
    "        X_test_true.append(records_selection[i])\n",
    "        y_test_true.append(labels[i])\n",
    "        \n",
    "        cnt +=1\n",
    "    if cnt >= 200:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_true = np.array(X_train_true)\n",
    "y_train_true = np.array(y_train_true)\n",
    "X_test_true = np.array(X_test_true)\n",
    "y_test_true = np.array(y_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train_true)\n",
    "np.save('y_train.npy', y_train_true)\n",
    "np.save('X_test.npy', X_test_true)\n",
    "np.save('y_test.npy', y_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "x2 = np.load('y_test.npy')\n",
    "# print the array\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b955d226d9aa9f90a51fa3f36ce22332332eca7b3eabee7dfc09f1063aca4ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
